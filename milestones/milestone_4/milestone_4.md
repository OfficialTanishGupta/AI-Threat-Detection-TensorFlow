# Milestone 4: Pose Detection & Motion Feature Extraction

## ğŸ“Œ Objective

The objective of this milestone is to detect human body pose from video
and extract **motion-based numerical features** required for behavior analysis.

This milestone bridges **raw video input** and **ML-based behavior classification**.

---

## ğŸ§  Problem Solved

Object detection alone is insufficient to understand intent.
Pose-based motion analysis enables understanding:

- Body posture
- Arm movement
- Motion intensity

These signals are critical for intelligent surveillance systems.

---

## ğŸ¥ Input

- Video footage (`pose_detection_demo.mp4`)
- Single-person visible in frame

---

## ğŸ§© Technologies Used

- Python
- OpenCV
- MediaPipe Pose
- Google Colab (for visualization)

---

## ğŸ—ï¸ Pipeline Overview

```text
Video
 â†“
Frame Extraction
 â†“
RGB Conversion
 â†“
Pose Landmark Detection
 â†“
Skeleton Visualization
 â†“
Motion Feature Extraction



## ğŸ“ Pose Landmarks Used

RIGHT_SHOULDER

RIGHT_WRIST

These landmarks are used to compute arm posture and motion.

```

## ğŸ“Š Extracted Features

Feature Description
Arm Angle Vertical displacement between shoulder and wrist
Hand Speed Frame-to-frame wrist movement

## ğŸ§ª Sample Output

Frame read: True
Arm Angle: 108.34
Hand Speed: 0.0321

## Visualization

Skeleton overlay on person

5 sample frames displayed per run (Colab-safe)

Real-time feature values printed per frame

## âœ… Results

âœ”ï¸ Video frames successfully read
âœ”ï¸ Pose detected reliably
âœ”ï¸ Skeleton drawn on person
âœ”ï¸ Numerical motion features extracted

## ğŸš€ Real-World Application

This milestone enables:

Suspicious activity analysis

Gesture-based threat detection

Input preparation for ML classifiers
